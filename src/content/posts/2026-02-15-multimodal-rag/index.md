---
title: "Multimodal RAG: Beyond Text Embeddings (Korean)"
description: "Index images and audio directly; use cross-modal retrieval."
date: "2026-02-15"
image: "/images/blog/default-ai.jpg"
tags: ["AI", "Tech", "multimodal-rag"]
---

# 멀티모달 RAG: 텍스트 임베딩을 넘어서

## 소개 (Introduction)

검색 증강 생성(RAG, Retrieval-Augmented Generation)은 우리가 AI 애플리케이션을 구축하는 방식을 근본적으로 변화시켰으며, 대규모 언어 모델(LLM)이 재학습 없이도 독점 데이터에 액세스할 수 있게 했습니다. 하지만 최근까지 "데이터"는 거의 전적으로 "텍스트"를 의미했습니다. 우리는 PDF를 청크로 나누고, 웹사이트를 스크랩하고, 문서를 벡터화하는 파이프라인을 구축해 왔지만, 텍스트가 아닌 형식에 갇혀 있는 방대한 정보의 우주는 간과해 왔습니다.

Gemini 1.5 Pro나 GPT-4o와 같은 모델들이 멀티모달 이해를 보편화함에 따라, 검색 시스템을 텍스트 임베딩으로만 제한하는 것은 구시대적 제약(legacy constraint)이 되고 있습니다. 멀티모달 RAG는 이 아키텍처의 다음 진화 단계로, 시스템이 텍스트를 처리하는 것만큼 유창하게 이미지, 오디오, 비디오를 검색하고 추론할 수 있게 합니다. 이는 단순히 이미지를 OCR 처리하여 텍스트를 검색하는 것이 아닙니다. 시각적 또는 청각적 데이터 자체의 의미적 내용을 이해하는 것입니다.

## 분석 (Analysis)

전통적인 RAG 파이프라인은 텍스트 임베딩 모델(OpenAI의 `text-embedding-3` 또는 오픈 소스 등가물 등)에 크게 의존합니다. 멀티모달 환경에서는 데이터의 형태(modality)와 관계없이 데이터를 공유된 의미 공간(semantic space)에 임베딩할 수 있는 모델로 전환해야 합니다.

### 텍스트 전용 프록시의 한계 (The Limitation of Text-Only Proxies)

역사적으로 RAG에서 이미지를 다루는 것은 시각-언어 모델(VLM)을 사용하여 캡션을 생성하고 그 캡션을 인덱싱하는 것을 의미했습니다. 기본적인 검색에는 효과적이지만, 이 접근 방식은 정보 손실이 발생합니다. "매출 성장을 보여주는 차트"라는 캡션은 사용자의 쿼리가 실제로 찾고자 하는 구체적인 데이터 포인트, 추세선, 그리고 시각적 뉘앙스를 담아내지 못합니다.

### 직접 인덱싱과 교차 모달 검색 (Direct Indexing and Cross-Modal Retrieval)

현대 멀티모달 RAG의 핵심 통찰은 **이미지와 오디오를 직접 인덱싱하고, 교차 모달 검색(cross-modal retrieval)을 사용하는 것**입니다.

모든 것을 텍스트로 변환하는 대신, 텍스트, 이미지, 그리고 잠재적으로 오디오를 동일한 벡터 공간에 매핑하는 멀티모달 임베딩 모델(CLIP 또는 Google의 Multimodal Embeddings 등)을 사용합니다.

1.  **공유 벡터 공간 (Shared Vector Space):** 이 고차원 공간에서 "공을 가지고 노는 골든 리트리버" 사진의 벡터는 "공을 가지고 달리는 개"라는 텍스트 문자열의 벡터와 수학적으로 가깝습니다.
2.  **네이티브 검색 (Native Retrieval):** 사용자가 "Q3 API 변경 사항을 논의한 회의 녹음을 찾아줘"라고 요청하면, 시스템은 단순히 대본(transcript)만 검색하지 않습니다. 쿼리를 회의의 오디오 임베딩과 직접적으로 의미론적으로 매칭하거나, 대본 벡터와 오디오 톤 벡터를 결합한 하이브리드 접근 방식을 사용할 수 있습니다.
3.  **원시 컨텍스트 주입 (Raw Context Injection):** 관련 비텍스트 청크가 검색되면, 원시 데이터(이미지 토큰 또는 오디오 프레임)가 멀티모달 LLM의 컨텍스트 윈도우로 전달됩니다. 이를 통해 모델은 파생된 텍스트 요약이 아닌, 차트의 실제 픽셀이나 오디오 클립의 특정 억양을 분석하여 원본 소스 자료에 대한 추론을 수행할 수 있습니다.

### 아키텍처의 변화 (Architectural Shifts)

이를 구현하려면 고차원 벡터를 지원하는 벡터 데이터베이스뿐만 아니라 다양한 파일 유형을 처리할 수 있는 메타데이터 스키마가 필요합니다. 더 이상 `text_chunk`만 저장하는 것이 아니라 `image_path` 또는 `audio_segment_timestamp`를 저장하게 됩니다.

게다가 재순위화(re-ranking) 전략은 더 복잡해집니다. 관련 이미지를 관련 텍스트 단락과 비교하여 어떻게 순위를 매길까요? LLM에 도달하기 전에 컨텍스트를 정제하기 위해 (쿼리, 이미지) 쌍의 점수를 매길 수 있는 크로스 인코더(cross-encoders)가 필수적입니다.

## 결론 (Conclusion)

텍스트는 웹의 보편적인 인터페이스이지만, 지식이 존재하는 유일한 형식은 아닙니다. 텍스트 임베딩을 넘어 교차 모달 검색을 수용함으로써, 개발자는 문서를 단순히 "읽는" 것이 아니라 그 안에 묘사된 세상을 "인식하는" 시스템을 구축할 수 있습니다.

멀티모달 RAG는 단순한 점진적 업그레이드가 아닙니다. 네이티브 멀티모달 모델 시대를 위한 필수적인 적응입니다. 오늘부터 멀티모달 임베딩 모델을 실험하고, 이미지와 오디오 파일을 벡터 데이터베이스에서 2등 시민으로 취급하는 관행을 버려야 합니다.