---
title: "Midjourney Character Consistency (Traditional Chinese)"
description: "使用角色參考（Character Reference）功能與提示詞框架，將徹底改變 AI 故事創作與繪本製作的流程。"
date: "2026-02-15"
image: "https://picsum.photos/seed/midjourney/800/600"
tags: ["AI", "Tech", "midjourney-v7-consistency"]
---

# 📝 告別崩壞！Midjourney 角色一致性 (Character Consistency) 終極提示詞框架

- **🎯 推薦對象：** AI 繪本作家、漫畫家、遊戲美術設計師、行銷人員
- **⏱️ 節省時間：** 數小時的算圖與修圖 → 3 分鐘內產出連貫分鏡
- **🤖 推薦模型：** ChatGPT (GPT-4o) / Claude 3.5 Sonnet + Midjourney v6/v7

- ⭐ **難易度：** ⭐⭐⭐☆☆
- ⚡️ **有效性：** ⭐⭐⭐⭐⭐
- 🚀 **實用度：** ⭐⭐⭐⭐⭐

> _"每次用 AI 畫連續故事，主角換個場景就像去了一趟韓國整型？利用這套「角色設定器」搭配 Midjourney 的 `--cref` 功能，讓你的 AI 主角永遠保持同一個靈魂。"_

在 AI 繪圖的實務應用中，保持「角色一致性（Character Consistency）」一直是創作者最大的痛點。過去我們依賴複雜的 Seed 值或繁瑣的墊圖技巧，現在，透過 Midjourney 強大的 `--cref` (Character Reference) 參數，結合大語言模型預先規劃好的分鏡提示詞，任何人都能輕鬆產出高水準的連續視覺故事。

---

## ⚡️ 3句話總結 (TL;DR)

1. 使用 ChatGPT 扮演「分鏡師」，幫你自動展開主角在不同場景的英文提示詞。
2. 掌握核心參數 `--cref [圖片網址]`，直接鎖定角色的 DNA 特徵。
3. 靈活運用 `--cw` 權重參數（100 代表完全複製包含服裝，0 代表只複製臉部特徵以便換裝）。

---

## 🚀 解決方案：Midjourney 角色連貫性產生器

### 🥉 Basic Version (基本型)

只需快速生成幾個連貫場景測試時使用。

> **角色：** 你是一位專業的 AI 繪圖提示詞工程師。
> **請求：** 請幫我生成 3 個用來測試「同一個女孩」的 Midjourney 英文提示詞。
> **要求：** 場景分別為「喝咖啡」、「在雨中撐傘」、「看著星空」。請在每個提示詞結尾自動加上 `--cref [角色圖片網址] --cw 100 --v 6.0`。

<br>

### 🥇 Pro Version (專家型)

適用於正式連載漫畫、繪本製作，需要精細控制角色換裝與複雜動作時使用。

> **角色 (Role):** 你是一位頂級的 AI 漫畫分鏡師與 Midjourney 提示詞專家。
>
> **情況 (Context):**
>
> - 背景：我正在創作一部高品質的視覺故事，需要讓同一位主角出現在各種不同場景中，且必須維持極高的「角色一致性（Character Consistency）」。
> - 目標：透過精準的提示詞結構，配合 Midjourney 的 `--cref` 與 `--cw` 參數，產生完美連貫的畫面。
>
> **任務 (Task):**
>
> 1. 請先向我詢問主角的基本設定（年齡、性別、髮型、特徵）以及故事的主題。
> 2. 根據我的回覆，生成 5 個不同場景與服裝的 Midjourney 英文提示詞。
> 3. 提示詞必須遵循以下結構：`[主體核心特徵] + [動作與表情] + [服裝描述] + [場景與光影] + [攝影機與藝術風格] + [參數]`。
>
> **限制條件 (Constraints):**
>
> - 每個生成的 Midjourney 提示詞請以**程式碼區塊（Code Block）**輸出，方便我直接複製。
> - 所有提示詞主體內容必須使用英文撰寫。
> - **換裝場景**的提示詞，參數必須包含 `--cw 0`（允許改變服裝）；**不換裝的場景**請使用 `--cw 100`（保留原服裝）。
> - `[角色圖片網址]` 請明確保留為變數，讓我後續自行替換。
>
> **注意事項 (Warning):**
>
> - 提示詞中不要包含可能導致畫面衝突的描述。
> - 不要擅自改變角色的核心特徵（如髮色、瞳孔顏色）。

---

## 💡 作者見解 (Insight)

這個框架最大的價值在於**「分離變數」**。直接在 Midjourney 裡盲測很容易迷失方向。透過讓 ChatGPT 先把角色的核心特徵（如 _freckles, short black hair, green eyes_）固定下來，再疊加 `--cref` 參數，等於上了「雙重保險」。

特別是 `--cw` (Character Weight) 參數的運用非常關鍵。當你將 `--cw` 設為 100 時，Midjourney 會試圖還原原圖的臉部和**衣服**。如果你想要讓主角換裝，請務必將 `--cw` 設為 0，這樣 AI 就會**只專注於保留臉部特徵**，讓你能在提示詞中自由更換角色的服飾。這對於製作有連貫劇情的專案來說，是個無價的技巧！

---

## 🙋 常見問題 (FAQ)

- **Q: `--cref` 可以同時參考多張圖片嗎？**
  - A: 可以的！你可以連續加上多個網址（例如 `--cref url1 url2`），Midjourney 會融合這些圖片的角色特徵。這對於創造一個獨一無二且穩定的原創角色非常有用。

- **Q: 為什麼出來的角色還是有點不像？**
  - A: 參考圖片的品質決定了結果。請盡量使用臉部清晰、無誇張表情、光線均勻且沒有過多遮擋物（如大墨鏡、複雜帽子）的半身照作為 `--cref` 的來源圖。

- **Q: 這個功能對真人照片有效嗎？**
  - A: 有效，但會稍微被 AI 「風格化」。它並不是設計來做完美的 Deepfake（換臉），而是用來維持 AI 生成角色的外觀一致性。

---

## 🧬 提示詞解剖 (Why it works?)

1.  **Role & Task 結合:** 直接讓 LLM 扮演分鏡師，能確保輸出的提示詞具有畫面感與故事張力。
2.  **自動化參數配置:** 透過約束條件（Constraints）讓 AI 判斷何時該用 `--cw 0`（換裝）或 `--cw 100`（不換裝），大幅減少人工修改參數的麻煩。
3.  **結構化輸出:** 強制使用 Code Block 輸出，實現了真正的 "Copy & Paste" 工作流，節省了大量在 Discord 中反覆編輯的時間。

---

## 📊 證明：Before & After

### ❌ Before (沒有使用框架，盲目生成)

每一次生成的女孩長相都略有不同，衣服風格跳脫，無法確認是同一位主角，難以串接成完整故事。

### ✅ After (使用提示詞框架與 `--cref`)

**ChatGPT 輸出的提示詞範例：**

```text
A 25-year-old woman with short black hair and freckles, wearing a sleek silver cyberpunk jacket, sitting in a neon-lit futuristic cafe, sipping coffee, rain on the window, cinematic lighting, 8k resolution --ar 16:9 --cref [角色圖片網址] --cw 0 --v 6.0
```

_(複製到 Midjourney 後)_ 主角在咖啡廳、在太空船上、在雨中漫步，雖然場景與服裝完全不同，但那張臉和神韻，一眼就能認出是同一個人！

---

## 🎯 結論

Midjourney 的角色一致性功能，不僅僅是技術上的更新，更是說故事方式的革命。搭配 AI 語言模型的提示詞框架，阻擋你創作連載漫畫的，不再是畫工，而是你的想像力。

快去創造屬於你的專屬角色宇宙吧！ 🚀
